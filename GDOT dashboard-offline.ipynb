{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clint/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/clint/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clint/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/clint/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/clint/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Normalizer from version 0.24.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46812\n",
      "6189\n",
      "6224\n",
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import sympy\n",
    "from sympy import *\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "# set working dir\n",
    "working_dir = '/home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI'\n",
    "os.chdir(working_dir)\n",
    "from project_tools import load_obj, interact, save_obj\n",
    "pipe = load_obj('pickel_pipe_minMax_fixed_full')\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# load model\n",
    "from kerasncp import wirings\n",
    "from kerasncp.tf import LTCCell\n",
    "\n",
    "LSTM_model = keras.models.load_model('models/models_universal/LSTM_Global.epoch01.hdf5')\n",
    "LTC_model = keras.models.load_model('models/models_universal/LTC_Global_v6.epoch07.hdf5')\n",
    "\n",
    "\"\"\"\n",
    "VDS data functions\n",
    "\"\"\"\n",
    "#vpn.dot.ga.gov\n",
    "private_info = {'username': 'C0007419','password': 'GreatDay2021'}\n",
    "private_info['password'] = 'GreatDay2021'\n",
    "\n",
    "\"\"\"\n",
    "load all data_processing helper functions\n",
    "\"\"\"\n",
    "from data_processing import *\n",
    "\"\"\"\n",
    "load vae models\n",
    "\"\"\"\n",
    "from VAE_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [10/Jun/2021 19:34:18] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Jun/2021 19:34:19] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Jun/2021 19:34:19] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KGASTONE28\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/flask/app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/dash/dash.py\", line 1078, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/site-packages/dash/dash.py\", line 1009, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-2-17245b5066b7>\", line 211, in get_vds_data\n",
      "    url, urlb4 = generate_url(station, Start_Date.strip(), SQL_URL=GDOT_SQL)\n",
      "  File \"/home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/data_processing.py\", line 101, in generate_url\n",
      "    date_1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/_strptime.py\", line 577, in _strptime_datetime\n",
      "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
      "  File \"/home/clint/anaconda3/lib/python3.7/_strptime.py\", line 359, in _strptime\n",
      "    (data_string, format))\n",
      "ValueError: time data '' does not match format '%Y-%m-%d'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jun/2021 19:34:19] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-04\n",
      "KGASTONE28\n",
      "https://www.wunderground.com/history/daily/us/ga/lilburn/KGASTONE28/date/2019-08-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/data_processing.py:340: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 340 of the file /home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/data_processing.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating recurrence images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating recurrence images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating wavelet images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating wavelet images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jun/2021 19:34:27] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-04\n",
      "KGASTONE28\n",
      "https://www.wunderground.com/history/daily/us/ga/lilburn/KGASTONE28/date/2019-08-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/data_processing.py:340: UserWarning:\n",
      "\n",
      "No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 340 of the file /home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/data_processing.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating recurrence images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating recurrence images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating wavelet images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "generating wavelet images...\n",
      "\u001b[34mDone!\u001b[0m\n",
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jun/2021 19:39:25] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "dynamic\n",
    "\"\"\"\n",
    "import dash\n",
    "from dash.dependencies import Output, Input\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly\n",
    "import random\n",
    "import plotly.graph_objs as go\n",
    "from collections import deque\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_daq as daq\n",
    "\n",
    "colors = {\n",
    "    'background': 'rgb(54,54,54)',\n",
    "    'text': 'rgb(255,255,255)',\n",
    "    'second': 'rgb(255,255,255)'\n",
    "}\n",
    "\n",
    "html_format = {\n",
    "    'right_col' : '25%',\n",
    "    'left_col' : '75%'\n",
    "}\n",
    "\n",
    "#innit driver\n",
    "num_workers = 3\n",
    "drivers = {}\n",
    "# url, urlb4 = generate_url('5917', '2019-08-04', SQL_URL=GDOT_SQL)\n",
    "for x in range(num_workers):\n",
    "    drivers[x] = webdriver.Chrome(executable_path = '/home/clint/temp/UGA-Masters/VDS_CCS_Project/GUI/GUI/chromedriver',\n",
    "                                  options=chrome_options)\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.Img(\n",
    "        src=\"https://i.ibb.co/HDDYFLp/logo-gdot.png\",\n",
    "        className='four columns',\n",
    "        style={\n",
    "                'height': '9%',\n",
    "                'width': '15%',\n",
    "                'float': 'right',\n",
    "                'position': 'relative',\n",
    "                'margin-top': 10,'margin-right': 25,}),\n",
    "        html.Img(\n",
    "        src=\"https://i.ibb.co/VHmK0rG/GEORGIA-FS-W-1024x335.png\",\n",
    "        className='four columns',\n",
    "        style={\n",
    "                'height': '9%',\n",
    "                'width': '15%',\n",
    "                'float': 'right',\n",
    "                'position': 'relative',\n",
    "                'margin-top': 10,'margin-right': 25,}),\n",
    "        \n",
    "        html.H1(\"UGA-GDOT Anomaly Detector\", style={'color': 'white'}),\n",
    "        html.Div(html.P([\n",
    "                        html.Div(html.Div([html.P('Collect Live Data',style={'color': 'white'}),\n",
    "                                   daq.ToggleSwitch(id='switch',value=False,)],\n",
    "                                 style={\"width\": \"90%\",'background-color': colors['background']}),\n",
    "                                 style={\"textAlign\":\"center\",\"width\": \"100%\", \"float\": \"center\",'marginTop': 130,\n",
    "                                        'fontColor': 'white','background-color': colors['background']}),\n",
    "            \n",
    "                        dcc.Input(id=\"Start_Date\", placeholder=\"Enter date: YYYY-MM-DD\",\n",
    "                                                    type='text',value='',\n",
    "                                                    style={'marginTop': 25, \"width\": \"95%\",'marginLeft': 25,\n",
    "                                                           'background-color': colors['second'],}),\n",
    "            \n",
    "                        dcc.Loading(id=\"Start_Date-1\",type=\"default\",\n",
    "                                                    children=html.Div(id=\"Start_Date-output-1\"),),\n",
    "                         \n",
    "                        dcc.Dropdown(id='dd_station', options=OptionList,\n",
    "                                                    value='5917',\n",
    "                                                    placeholder=\"Select VDS Station\",\n",
    "                                                    style={\"textAlign\":\"left\",\"width\": \"95%\",\n",
    "                                                           'marginLeft': 25,'marginTop': 25,\n",
    "                                                           'background-color': colors['second']})],\n",
    "            \n",
    "                                                    style={'color':'black','fontColor': 'white'}),\n",
    "\n",
    "                         \n",
    "            style={\"textAlign\":\"right\",\"width\": html_format['right_col'], \"float\": \"left\",'color':'black'},\n",
    "        ),\n",
    "        dcc.Graph(id=\"graph\", style={\"width\": html_format['left_col'], \"display\": \"inline-block\",\"height\": \"200%\",},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "        \n",
    "        html.Div(html.Div(html.Iframe(id='map', srcDoc=open('static/assets/matched.html', 'r').read(), \n",
    "                                      title='VDS: Blue, CCS: Red',width='100%', height='320'),\n",
    "                style={\"width\": \"90%\",\"display\":\"inline-block\",'marginLeft': \"7%\",'backgroundColor': colors['background']}),\n",
    "                 style={\"width\": html_format['right_col'],\"display\":\"inline-block\",\"height\": \"100%\",\n",
    "                        \"float\": \"left\", 'backgroundColor': colors['background']}),\n",
    "                 \n",
    "        dcc.Graph(id=\"graph-re\", style={\"width\": html_format['left_col'], \"display\": \"inline-block\",\"height\": \"200%\", \"float\": \"right\"},\n",
    "                        figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "        dcc.Graph(id=\"graph-we\", style={\"width\": html_format['left_col'], \"display\": \"inline-block\",\"height\": \"200%\", 'marginLeft': html_format['right_col']},\n",
    "                        figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "        \n",
    "        \n",
    "        # fig row one and two\n",
    "        html.Div(html.Div([\n",
    "            \n",
    "                dcc.Graph(id=\"image1\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "                dcc.Graph(id=\"image2\", style={\"display\": \"inline-block\",\"height\": '27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "            \n",
    "                # newly added\n",
    "                dcc.Graph(id=\"image3\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "                dcc.Graph(id=\"image4\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}})\n",
    "        \n",
    "        \n",
    "        ],\n",
    "                         style={'paper_bgcolor': colors['background'],'marginLeft': '25%'}),\n",
    "                         style={\"width\": '100%',\"display\":\"inline-block\",\"height\": \"100%\",\n",
    "                                'backgroundColor': colors['background']}),\n",
    "\n",
    "        # fig row one and two\n",
    "        html.Div(html.Div([\n",
    "            \n",
    "                dcc.Graph(id=\"image5\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "                dcc.Graph(id=\"image6\", style={\"display\": \"inline-block\",\"height\": '27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "            \n",
    "                # newly added\n",
    "                dcc.Graph(id=\"image7\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}}),\n",
    "                dcc.Graph(id=\"image8\", style={\"display\": \"inline-block\",\"height\":'27%',\"width\":'24%',\"float\":\"left\"},\n",
    "                         figure={'data': [],'layout': {'plot_bgcolor': colors['background'],\n",
    "                                'paper_bgcolor': colors['background'],\n",
    "                                'font': {'color': colors['text']}}})\n",
    "        \n",
    "        \n",
    "        ],\n",
    "                         style={'paper_bgcolor': colors['background'],'marginLeft': '25%'}),\n",
    "                         style={\"width\": '100%',\"display\":\"inline-block\",\"height\": \"100%\",\n",
    "                                'backgroundColor': colors['background']}),\n",
    "             \n",
    " \n",
    "        \n",
    "        dcc.Interval(id='graph-update',interval=5*60*1000),\n",
    "#         dcc.Interval(id='graph-update',interval=10*1000),\n",
    "        dcc.Store(id='intermediate_value'),\n",
    "        \n",
    "#         html.Footer(html.P(\"Smart Mobility and Infrastructure Lab\", style={'color': 'white',\"textAlign\":\"center\"}))\n",
    "    ],style={'backgroundColor': colors['background'],'color':'white','fontColor': 'white'})\n",
    "\n",
    "\n",
    "@app.callback([Output(\"graph\", \"figure\"),\n",
    "               Output(\"graph-re\", \"figure\"),\n",
    "               Output(\"graph-we\", \"figure\"),\n",
    "               Output(\"Start_Date-output-1\", \"children\"),\n",
    "               Output('image1', 'figure'),\n",
    "               Output('image2', 'figure'),\n",
    "               Output('image3', 'figure'),\n",
    "               Output('image4', 'figure'),\n",
    "               Output('image5', 'figure'),\n",
    "               Output('image6', 'figure'),\n",
    "               Output('image7', 'figure'),\n",
    "               Output('image8', 'figure'),\n",
    "               Output('intermediate_value', 'data'),\n",
    "               \n",
    "              ],\n",
    "              \n",
    "              [Input(\"switch\", \"value\"),\n",
    "               Input(\"Start_Date\", \"value\"), \n",
    "               Input('dd_station',\"value\"),\n",
    "               Input('graph-update', 'n_intervals'),\n",
    "               Input('intermediate_value', 'value')])\n",
    "\n",
    "def get_vds_data(switch, Start_Date, dd_station, input_data, intermediate_value, GDOT_SQL=GDOT_SQL, drivers=drivers):\n",
    "    \n",
    "    data = {}\n",
    "    station=dd_station\n",
    "    if switch == False:\n",
    "        print(Start_Date)\n",
    "        \n",
    "        weather_station = vds2weatherStation[station]\n",
    "        print(weather_station)\n",
    "\n",
    "        now_ = datetime.datetime.now()\n",
    "        date, hr, min_, _ = now_.strftime(\"%Y-%m-%d %H %M %S\").split()\n",
    "\n",
    "        url, urlb4 = generate_url(station, Start_Date.strip(), SQL_URL=GDOT_SQL)\n",
    "        \n",
    "        # load urls\n",
    "        get_weather_url(drivers[2], Start_Date, station=weather_station)\n",
    "        \n",
    "#         drivers[0].get(urlb4)\n",
    "#         drivers[1].get(url) # get location\n",
    "\n",
    "#         # get vds data\n",
    "#         dfs = {}\n",
    "#         for x in range(2):\n",
    "#             banner =  interact(drivers[x], GDOT_SQL['banner'],click=False,delay=0.02,count=350,status_rate=300) \n",
    "#             dfs[x] = get_table(drivers[x]) # scrape data from driver \n",
    "\n",
    "        weather_data = get_weather_data(drivers[2])\n",
    "\n",
    "        # preprocessing two days of data for predicting\n",
    "#         flat_arr = np.array(dfs[0]['TOT VOL'].tolist() + dfs[1]['TOT VOL'].tolist())\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        get ccs/vds offline data here\n",
    "        \"\"\"\n",
    "        df_offline_data = pd.read_csv(f'data/historic_ccs_vds_data/{station}.csv')\n",
    "        \n",
    "        date_1 = datetime.datetime.strptime(Start_Date, \"%Y-%m-%d\")\n",
    "        dayb4 = date_1 + datetime.timedelta(days=-1)\n",
    "        dayb4 = dayb4.strftime(\"%Y-%m-%d\")\n",
    "        df_offline_data = df_offline_data[df_offline_data['date'].isin([dayb4,Start_Date])]\n",
    "        flat_arr = df_offline_data['vds_vol'].to_numpy()\n",
    "        \n",
    "        df_offline_data_sub = df_offline_data[df_offline_data['date']==Start_Date]\n",
    "        time_list = list(df_offline_data_sub['time'])\n",
    "        true_vds = df_offline_data_sub['vds_vol']\n",
    "        \n",
    "        \"\"\"\n",
    "        Predict data\n",
    "        \"\"\"\n",
    "        pred = predict_vds(flat_arr, LTC_model, LTC=True)\n",
    "        pred_LSTM = predict_vds(flat_arr, LSTM_model, LTC=False)\n",
    "\n",
    "        \"\"\"\n",
    "        Get images \n",
    "        \"\"\"\n",
    "        X_transformed_vds = get_im_transf(true_vds, pipeline_image)\n",
    "        X_transformed = get_im_transf(df_offline_data_sub['ccs_vol'], pipeline_image)\n",
    "\n",
    "        \"\"\"\n",
    "        Recurrence plots\n",
    "        \"\"\"\n",
    "        reshape_size_recur = 32 # move later\n",
    "        n_scales = 64\n",
    "        reshape_size = 64\n",
    "        interval_len = 288\n",
    "        \n",
    "        recur_data = collect_recurrence_data(X_transformed, reshape_size_recur)\n",
    "        recur_data_re = recur_data.reshape(-1, reshape_size_recur, reshape_size_recur, 1) # ccs data\n",
    "        recur_data_vds = collect_recurrence_data(X_transformed_vds, reshape_size_recur)\n",
    "        recur_data_re_vds = recur_data_vds.reshape(-1, reshape_size_recur, reshape_size_recur, 1) # vds data\n",
    "        \n",
    "        Recur_Zenc_vds = encoder_model_recur.predict(recur_data_re_vds)[0]\n",
    "        pred_recur_vds = decoder_model_recur.predict(np.array([Recur_Zenc_vds[0].tolist()])).reshape(reshape_size_recur, -1)\n",
    "        Recur_Zenc = encoder_model_recur.predict(recur_data_re)[0]\n",
    "        pred_recur = decoder_model_recur.predict(np.array([Recur_Zenc[0].tolist()])).reshape(reshape_size_recur, -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        wavelet plots\n",
    "        \"\"\"\n",
    "        cwt_data = collect_cwt_data(X_transformed, reshape_size, n_scales, interval_len=interval_len) # make wavelet images\n",
    "        cwt_data_re = cwt_data.reshape(-1, reshape_size, reshape_size, 1) # format for CNN\n",
    "        cwt_data_vds = collect_cwt_data(X_transformed_vds, reshape_size, n_scales, interval_len=interval_len)# param same as CCS\n",
    "        cwt_data_re_vds = cwt_data_vds.reshape(-1, reshape_size, reshape_size, 1)\n",
    "        \n",
    "        Zenc_ccs = encoder_model.predict(cwt_data_re)[0]\n",
    "        pred_wavelet = decoder_model.predict(np.array([Zenc_ccs[0].tolist()])).reshape(reshape_size, -1)\n",
    "        Zenc_vds = encoder_model.predict(cwt_data_re_vds)[0]\n",
    "        pred_wavelet_vds = decoder_model.predict(np.array([Zenc_vds[0].tolist()])).reshape(reshape_size, -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        get score\n",
    "        \"\"\"\n",
    "        double_vds = np.concatenate((Zenc_vds, Recur_Zenc_vds), axis=1)[0]\n",
    "        double_ccs = np.concatenate((Zenc_ccs, Recur_Zenc), axis=1)[0]\n",
    "        \n",
    "        d_vds, d_ccs, d3 = getNearestNeighborV2(space, double_vds, double_ccs, zeros=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        format weather\n",
    "        \"\"\"\n",
    "        simple_weather = [format_conditions(x) for x in weather_data] # simplify cats\n",
    "        val_weather = [group2val[x] for x in simple_weather] # cat to weather\n",
    "        weather_data = [f'{time} {weather}' for weather, time in zip(weather_data,time_list)]\n",
    "\n",
    "        f, indic = [], 0 # frequency and indicator\n",
    "        for idx, val in enumerate(val_weather):\n",
    "            if val>indic:\n",
    "                indic=val\n",
    "            f = f + [idx]*(1+val)\n",
    "            \n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=time_list, y=(list(df_offline_data['ccs_vol'].astype(float))),\n",
    "                    mode='lines+markers',\n",
    "                    name='CCS'))\n",
    "        fig.add_trace(go.Scatter(x=time_list, y=(list(true_vds.astype(float))),\n",
    "                        mode='lines+markers',\n",
    "                        name='VDS'))\n",
    "        fig.add_trace(go.Scatter(x=time_list, y=(list(pred.astype(float))),\n",
    "                        mode='lines+markers',\n",
    "                        name='VDS LTC      '))\n",
    "        fig.add_trace(go.Scatter(x=time_list, y=(list(pred_LSTM.astype(float))),\n",
    "                        mode='lines+markers',\n",
    "                        name='VDS LSTM'))\n",
    "        fig.update_layout(title=f\"VDS {vds2stationName[station]} Volume Data: {Start_Date}\",\n",
    "                          xaxis_title=\"Time\",\n",
    "                          yaxis_title=\"Total Volumn\",\n",
    "                          height=500,\n",
    "                          #legend_title=\"\",\n",
    "                          font=dict(\n",
    "                                family=\"Courier New, monospace\",\n",
    "                                size=16,\n",
    "                                color=\"white\"),\n",
    "                          plot_bgcolor = colors['background'],\n",
    "                          paper_bgcolor = colors['background'],)\n",
    "\n",
    "\n",
    "\n",
    "        diff = true_vds.astype(float) - pred.astype(float)\n",
    "        list_diff = list(diff)\n",
    "        \n",
    "        anoms = np.where(abs(diff)>60)[0]\n",
    "        amoms_vals = [list_diff[x] for x in anoms]\n",
    "        anoms_times = [time_list[x] for x in anoms]\n",
    "\n",
    "        \n",
    "        fig_resid = go.Figure()\n",
    "        fig_resid.add_trace(go.Scatter(x=time_list, y=(list(diff)),\n",
    "                    mode='lines+markers',name=''))\n",
    "        fig_resid.add_trace(go.Scatter(x=time_list, y=(list(diff)),\n",
    "                    mode='lines+markers',name='Residuals    ',))\n",
    "        \n",
    "        # anomalies points\n",
    "        fig_resid.add_trace(go.Scatter(x=(anoms_times), y=(amoms_vals),\n",
    "                    mode='markers', name='Anomalies',\n",
    "                    marker=dict(color='yellow',size=16,\n",
    "                                line=dict(color='black',width=2))))\n",
    "\n",
    "        fig_resid.update_layout(title=f\"VDS Relative Error\",\n",
    "                      xaxis_title=\"Time\",\n",
    "                      yaxis_title=\"Total Volumn\",\n",
    "                      height=500,\n",
    "                      legend_title=\"       \",\n",
    "                      font=dict(\n",
    "                            family=\"Courier New, monospace\",\n",
    "                            size=16,\n",
    "                            color=\"white\"),\n",
    "                      plot_bgcolor = colors['background'],\n",
    "                      paper_bgcolor = colors['background'],)\n",
    "        fig_resid.update_yaxes(range=[(-np.max(true_vds.astype(float))), (np.max(true_vds.astype(float)))])\n",
    "    \n",
    "    \n",
    "\n",
    "        group_labels = '             '\n",
    "        color_ops = {2:'red',1:'orange',0:'blue'}\n",
    "        color_ = color_ops[indic]\n",
    "        fig_weather = go.Figure(data=[\n",
    "        go.Bar(name='             ', x=weather_data, y=val_weather, marker_color=color_),\n",
    "        go.Bar(name='', x=weather_data, y=[0 for x in range(288)])])\n",
    "        # Change the bar mode\n",
    "        fig_weather.update_layout(title_text=f'Potential Impact of Weather on VDS Operation: {weather_station}',\n",
    "                          yaxis = dict(\n",
    "                                tickmode = 'array',\n",
    "                                tickvals = [0,1,2],\n",
    "                                ticktext = ['Low ', 'High ', 'Severe ']),\n",
    "                                xaxis_title=\"Time\",\n",
    "    #                             yaxis_title=\"Total Volumn\",\n",
    "                                height=500,\n",
    "                                font=dict(\n",
    "                                    family=\"Courier New, monospace\",\n",
    "                                    size=16,\n",
    "                                    color=\"white\"),\n",
    "                                plot_bgcolor = colors['background'],\n",
    "                                paper_bgcolor = colors['background'],)\n",
    "        fig_weather.update_yaxes(range=[0, 2.1])\n",
    "        \n",
    "        \n",
    "        image1 = create_plot(recur_data[0], f'Recurrence CCS:', full_label='True Plots')\n",
    "        image2 = create_plot(recur_data_vds[0], f'Recurrence VDS:')\n",
    "        image3 = create_plot(cwt_data[0], f'Wavelet CCS:')\n",
    "        image4 = create_plot(cwt_data_vds[0], f'Wavelet VDS:')  \n",
    "  \n",
    "        #d_vds, d_ccs, d3\n",
    "        binary_scores = [0,0,0]\n",
    "        result, score = '', 0\n",
    "        for idx, (thresh, val) in enumerate(zip([4.4, 4.4, 3.90],[d_vds, d_ccs, d3])):\n",
    "            if val > thresh:\n",
    "                binary_scores[idx] = 1\n",
    "    \n",
    "#         if (binary_scores[0] == 1) or (binary_scores[1] == 1) or (binary_scores[2] == 1):\n",
    "        if (binary_scores[0] == 1) or (binary_scores[1] == 1):\n",
    "            result, score = 'Anomalous Data', 10\n",
    "            if (binary_scores[2] == 0): #check false positives\n",
    "                result, score = 'Organic Anomaly', 0\n",
    "\n",
    "\n",
    "        image5 = create_plot(pred_recur, f'Predicted Recurrence CCS:', \n",
    "                             f'Score VDS: {round(d_vds,2)}',\n",
    "                             score=score)\n",
    "        image6 = create_plot(pred_recur_vds, f'Predicted Recurrence VDS:',\n",
    "                             f'Score CCS: {round(d_ccs,2)}',\n",
    "                            score=score)\n",
    "        image7 = create_plot(pred_wavelet, f'Predicted Wavelet CCS:',\n",
    "                             f'Score Cross: {round(d3,2)}',\n",
    "                             score=score)\n",
    "        image8 = create_plot(pred_wavelet_vds, f'Predicted Wavelet VDS:',\n",
    "                            f'{result}',\n",
    "                             score=score)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return [fig, fig_resid, fig_weather, 'loaded', \n",
    "                image1, image2, image3, image4,\n",
    "                image5, image6, image7, image8,\n",
    "                data,]\n",
    "        \n",
    "        \n",
    "    \n",
    "#     pred, y_true, pred_LSTM, times, cut, old_hr, old_min = get_live_full(drivers[0])\n",
    "\n",
    "    Start_Date = '2020-04-04'\n",
    "\n",
    "    \"\"\"\n",
    "    get ccs/vds offline data here\n",
    "    \"\"\"\n",
    "    df_offline_data = pd.read_csv(f'data/historic_ccs_vds_data/{station}.csv')\n",
    "\n",
    "    date_1 = datetime.datetime.strptime(Start_Date, \"%Y-%m-%d\")\n",
    "    dayb4 = date_1 + datetime.timedelta(days=-1)\n",
    "    dayb4 = dayb4.strftime(\"%Y-%m-%d\")\n",
    "    df_offline_data = df_offline_data[df_offline_data['date'].isin([dayb4,Start_Date])]\n",
    "    flat_arr = df_offline_data['vds_vol'].to_numpy()\n",
    "\n",
    "    df_offline_data_sub = df_offline_data[df_offline_data['date']==Start_Date]\n",
    "    time_list = list(df_offline_data_sub['time'])[:input_data]\n",
    "    true_vds = df_offline_data_sub['vds_vol']\n",
    "    \n",
    "    \"\"\"\n",
    "    Predict data\n",
    "    \"\"\"\n",
    "    pred = predict_vds(flat_arr, LTC_model, LTC=True)\n",
    "    pred_LSTM = predict_vds(flat_arr, LSTM_model, LTC=False)\n",
    "    \n",
    "        \n",
    "    fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=time_list, y=(list(df_offline_data['ccs_vol'].astype(float))[:input_data]),\n",
    "#                 mode='lines+markers',\n",
    "#                 name='CCS'))\n",
    "    fig.add_trace(go.Scatter(x=time_list, y=(list(true_vds.astype(float))[:input_data]),\n",
    "                    mode='lines+markers',\n",
    "                    name='VDS'))\n",
    "    fig.add_trace(go.Scatter(x=time_list, y=(list(pred.astype(float))[:input_data]),\n",
    "                    mode='lines+markers',\n",
    "                    name='VDS LTC      '))\n",
    "    fig.add_trace(go.Scatter(x=time_list, y=(list(pred_LSTM.astype(float))[:input_data]),\n",
    "                    mode='lines+markers',\n",
    "                    name='VDS LSTM'))\n",
    "    fig.update_layout(title=f\"VDS {vds2stationName[station]} Volume Data: 2021-05-07\",\n",
    "                      xaxis_title=\"Time\",\n",
    "                      yaxis_title=\"Total Volumn\",\n",
    "                      height=500,\n",
    "                      #legend_title=\"\",\n",
    "                      font=dict(\n",
    "                            family=\"Courier New, monospace\",\n",
    "                            size=16,\n",
    "                            color=\"white\"),\n",
    "                      plot_bgcolor = colors['background'],\n",
    "                      paper_bgcolor = colors['background'],)\n",
    "\n",
    "    \n",
    "    fig_weather = go.Figure()\n",
    "    fig_weather.update_layout(plot_bgcolor = colors['background'],paper_bgcolor = colors['background'],)\n",
    "    fig_resid = go.Figure()\n",
    "    fig_resid.update_layout(plot_bgcolor = colors['background'],paper_bgcolor = colors['background'],)\n",
    "    \n",
    "    \n",
    "    image = fig_resid\n",
    "\n",
    "    \n",
    "    return [fig, fig_resid, fig_weather, 'loaded', \n",
    "            image, image, image, image,\n",
    "            image, image, image, image,\n",
    "            data,]\n",
    "\n",
    "\n",
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-08-04\n",
    "2019-09-19\n",
    "2020-01-22\n",
    "<!-- 2019-10-10 -->\n",
    "2019-01-18\n",
    "2020-01-04\n",
    "\n",
    "2019-12-09\n",
    "2020-02-11\n",
    "2019-08-19\n",
    "\n",
    "2020-02-02 # no data\n",
    "\n",
    "2019-04-21 # anom ccs\n",
    "\n",
    "2019-12-14 # organic\n",
    "2020-01-07 # not the best # GDOT-STN-780984\n",
    "\n",
    "\n",
    "2019-03-08 # GDOT-STN-780984\n",
    "\n",
    "2020-03-17 # good data GDOT-STN-780984\n",
    "\n",
    "GDOT-STN-780998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-08-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
